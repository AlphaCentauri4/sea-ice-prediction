{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM,TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96809f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enabling Dynamic Memory Allocation\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb150c5",
   "metadata": {},
   "source": [
    "## Sea Ice Prediction - UNet\n",
    "\n",
    "### Loading Combined Data 1979-2021\n",
    "\n",
    "Only consider last 5 variables\n",
    "\n",
    "#### Features:\n",
    "longwave, rain_rate, snow_rate, sst, sea_ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ecb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.load('/content/drive/MyDrive/UMBC/Polar_Sea_Ice/Taki Data/whole_data.npy',allow_pickle=True)\n",
    "data = np.load('data/whole_data.npy',allow_pickle=True)\n",
    "land_mask = np.load(\"data/y_land_mask_actual.npy\",allow_pickle=True)\n",
    "\n",
    "target = data[:,:,:,9]\n",
    "data = data[:,:,:,-5:]\n",
    "\n",
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120deba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape y_land_mask\n",
    "y_land_mask = land_mask.reshape(448, 304, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d732af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a lag to monthly targets\n",
    "lag = 6\n",
    "data = data[:-lag,:,:,:]\n",
    "target = target[lag:,:,:]\n",
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential split train:val data in 80:20 sequentially \n",
    "\n",
    "LEN_DATA = len(data) #total number of pixels\n",
    "\n",
    "NUM_TRAIN = LEN_DATA - 86 #reserve last 7 years for testing \n",
    "NUM_TEST = LEN_DATA - NUM_TRAIN\n",
    "\n",
    "print('LEN_DATA:',LEN_DATA)\n",
    "print('NUM_TRAIN:',NUM_TRAIN)\n",
    "print('NUM_TEST:',NUM_TEST)\n",
    "\n",
    "x_train = data[0:NUM_TRAIN]\n",
    "x_test = data[NUM_TRAIN:]\n",
    "\n",
    "#split features and labels\n",
    "y_train=target[:NUM_TRAIN] #target is last column i-e sea-ice\n",
    "y_test=target[NUM_TRAIN:] #target is last column i-e sea-ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train.shape:',x_train.shape)\n",
    "print('y_train.shape:',y_train.shape)\n",
    "\n",
    "print('x_test.shape:',x_test.shape)\n",
    "print('y_test.shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c462fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing all nans with Zeros\n",
    "x_train = np.nan_to_num(x_train)\n",
    "y_train = np.nan_to_num(y_train)\n",
    "x_test = np.nan_to_num(x_test)\n",
    "y_test = np.nan_to_num(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81bd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257faa53",
   "metadata": {},
   "source": [
    "### Reshaping Input and Target Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def reshape_features(dataset, months, lat, lon, features):\n",
    "    print(dataset.shape)\n",
    "    X = dataset.reshape(months, lat, lon, features)\n",
    "    return X\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def reshape_outcome(dataset, months, lat, lon):\n",
    "    print(dataset.shape)\n",
    "    X = dataset.reshape(months, lat, lon, 1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a1f5f1",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732da376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the features\n",
    "\n",
    "scaler_f = StandardScaler()\n",
    "x_train = scaler_f.fit_transform(x_train.reshape(-1,x_train.shape[2])) #reshaping to 2d for standard scaling\n",
    "x_test = scaler_f.transform(x_test.reshape(-1,x_test.shape[2])) #reshaping to 2d for standard scaling\n",
    "\n",
    "scaler_l = StandardScaler()\n",
    "y_train = scaler_l.fit_transform(y_train.reshape(-1,1)) #reshaping to 2d for standard scaling\n",
    "y_test = scaler_l.transform(y_test.reshape(-1,1)) #reshaping to 2d for standard scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping data to 3D for modeling\n",
    "lat = 448\n",
    "lon = 304\n",
    "features = 5\n",
    "x_train = reshape_features(x_train, NUM_TRAIN, lat, lon, features) # reshaping to 3d for model\n",
    "x_test = reshape_features(x_test, NUM_TEST, lat, lon, features) # reshaping to 3d for model\n",
    "\n",
    "y_train = reshape_outcome(y_train, NUM_TRAIN, lat, lon) # reshaping to 3d for model\n",
    "y_test = reshape_outcome(y_test, NUM_TEST, lat, lon) # reshaping to 3d for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d84299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train.shape:',x_train.shape)\n",
    "print('y_train.shape:',y_train.shape)\n",
    "\n",
    "print('x_test.shape:',x_test.shape)\n",
    "print('y_test.shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb829aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, Conv2D, ConvLSTM2D, BatchNormalization, UpSampling2D,MaxPooling2D, concatenate, Flatten, Reshape\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import load_model, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec732fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mse(y_true, y_pred):\n",
    "\ty_pred_masked = tf.math.multiply(y_pred, y_land_mask)\n",
    "\ty_true_masked = tf.math.multiply(y_true, y_land_mask)\n",
    "\tsquared_resids = tf.square(y_true_masked - y_pred_masked)\n",
    "\tloss = tf.reduce_mean(squared_resids)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f602c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (448, 304, 5)\n",
    "loss = custom_mse\n",
    "metrics = RootMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_batchnorm(input_shape, loss, metrics, learning_rate=1e-4, filter_size=3,\n",
    "                   n_filters_factor=1, n_forecast_months=1, use_temp_scaling=False,\n",
    "                   n_output_classes=1,\n",
    "                   **kwargs):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    conv1 = Conv2D(np.int(32*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(np.int(32*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    bn1 = BatchNormalization(axis=-1)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
    "\n",
    "    conv2 = Conv2D(np.int(64*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(np.int(64*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    bn2 = BatchNormalization(axis=-1)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
    "\n",
    "    conv3 = Conv2D(np.int(128*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(np.int(128*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    bn3 = BatchNormalization(axis=-1)(conv3)\n",
    "\n",
    "    up8 = Conv2D(np.int(64*n_filters_factor), 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2), interpolation='nearest')(bn3))\n",
    "    merge8 = concatenate([bn2,up8], axis=3)\n",
    "    conv8 = Conv2D(np.int(64*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(np.int(64*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    bn8 = BatchNormalization(axis=-1)(conv8)\n",
    "\n",
    "    up9 = Conv2D(np.int(32*n_filters_factor), 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2), interpolation='nearest')(bn8))\n",
    "    merge9 = concatenate([conv1,up9], axis=3)\n",
    "    conv9 = Conv2D(np.int(32*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(np.int(32*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(np.int(32*n_filters_factor), filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "\n",
    "    output = Conv2D(n_output_classes, 1, activation='linear')(conv9)\n",
    "        \n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=loss, metrics = metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc24ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_batchnorm(input_shape, loss, metrics)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define early stopping callback\n",
    "early_stopping = EarlyStopping(patience=100, restore_best_weights=True)\n",
    "\n",
    "# fit model\n",
    "print(x_train.shape, y_train.shape)\n",
    "history = model.fit(x=x_train, y=y_train,epochs=50,batch_size=32,validation_split=.2,verbose = 2)\n",
    "\n",
    "#\t\t\t\tcallbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_mse = model.evaluate(x_train, y_train)\n",
    "print(\"Train MSE: {:.4f}\\nTrain Loss: {:.4f}\".format(train_mse, train_loss))\n",
    "\n",
    "test_loss, test_mse = model.evaluate(x_test, y_test)\n",
    "print(\"Test MSE: {:.4f}\\nTest Loss: {:.4f}\".format(test_mse, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecasted values \n",
    "inv_y_pred = scaler_l.inverse_transform(y_pred.reshape(-1,1))\n",
    "\n",
    "# invert scaling for actual values\n",
    "inv_y_test = scaler_l.inverse_transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a14d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_y_pred = inv_y_pred.reshape(len(y_pred),448,304)\n",
    "print(inv_y_pred.shape)\n",
    "inv_y_test = inv_y_test.reshape(len(y_test),448,304)\n",
    "print(inv_y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730114a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_y_test[1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31962b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse = sqrt(mean_squared_error(inv_y_test.flatten(), inv_y_pred.flatten()))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "r_sq = r2_score(inv_y_test.flatten(), inv_y_pred.flatten())\n",
    "print('Test R_Square: %.3f' % r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Post-Process RMSE\n",
    "post_y = np.clip(inv_y_pred, a_min = 0, a_max = 100)\n",
    "rmse1 = sqrt(mean_squared_error(inv_y_test.flatten(), post_y.flatten()))\n",
    "print('Post-Process RMSE: %.3f' % rmse1)\n",
    "\n",
    "r_sq = r2_score(inv_y_test.flatten(), post_y.flatten())\n",
    "print('Post-Process R_Square: %.3f' % r_sq)\n",
    "\n",
    "mae = mean_absolute_error(inv_y_test.flatten(), post_y.flatten())\n",
    "print('Post-Process MAE: %.3f' % mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda SIC",
   "language": "python",
   "name": "anaconda-sea-ice-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
